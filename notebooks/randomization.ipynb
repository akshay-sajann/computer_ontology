{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPni-PC9Oa78","executionInfo":{"status":"ok","timestamp":1713736947758,"user_tz":-120,"elapsed":29815,"user":{"displayName":"A Sajan","userId":"06499805654190845226"}},"outputId":"c2287d1f-3179-4899-9dc5-6a229d4fabc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mordred in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Requirement already satisfied: six==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.16.0)\n","Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.25.2)\n","Requirement already satisfied: networkx==2.* in /usr/local/lib/python3.10/dist-packages (from mordred) (2.8.8)\n"]}],"source":["!pip install mordred\n","!pip install rdkit -q\n","!pip install scikit-multilearn -q\n","!pip install torchmetrics -q"]},{"cell_type":"code","source":["#Importing Libraries\n","import gc\n","import torch\n","import pickle\n","import statistics\n","import numpy as np\n","import pandas as pd\n","from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from rdkit.Chem import Descriptors\n","from rdkit.Chem import rdMolDescriptors\n","from mordred import Calculator, descriptors\n","from sklearn.feature_selection import RFECV\n","import statsmodels.stats.weightstats as stests\n","from sklearn.metrics import classification_report\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import RandomizedSearchCV\n","from skmultilearn.model_selection import IterativeStratification\n","from sklearn.metrics import make_scorer, roc_auc_score, precision_score, f1_score, recall_score\n","from torchmetrics.classification import MultilabelF1Score, MultilabelAUROC, MultilabelPrecision, MultilabelRecall"],"metadata":{"id":"kjppjxpnOpAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_list(input_str):\n","    \"\"\"\n","    Just changing the format of a column\n","    to make it workable\n","    \"\"\"\n","    cleaned_str = input_str.strip(\"[]\").replace(\"'\", \"\")\n","\n","    items = cleaned_str.split(',')\n","    items = [item.strip() for item in items]\n","\n","    formatted_str = ';'.join(items)\n","\n","    return formatted_str\n","\n","def check_and_replace(description):\n","    \"\"\"\n","    Iterates through a given \";\" separated strings\n","    and replaces them with the mapping assigned by\n","    any list labelled \"mapping\".\n","\n","    :param description: Text separated by ';'\n","    :type name: string\n","    :return: Text replaced according to the mapping\n","    :rtype: string\n","    \"\"\"\n","    descriptors = description.split(';')\n","    new_descriptors = []\n","\n","    for descriptor in descriptors:\n","        for row in replace:\n","            if descriptor == row[0]:\n","                new_descriptors.append(row[1])\n","\n","    return ';'.join(new_descriptors)\n","\n","def make_unique(labels):\n","   \"\"\"\n","   Takes a text separated by \";\" and makes them\n","   unique.\n","   \"\"\"\n","   return ';'.join(list(set(labels.split(';'))))\n","\n","def x_y_split(df):\n","  \"\"\"\n","  Splies the oncoming dataset to X and\n","  y for classification.\n","\n","  :param df: A molecular dataset for odor prediction\n","  :type df: pandas Dataframe\n","  :return: A list of classes/labels for each row.\n","  :rtype: pandas dataframes\n","  \"\"\"\n","  x = df[['IsomericSMILES', 'CID']].copy()\n","  try:\n","    y = df.drop(['IsomericSMILES', 'Descriptors', 'CID', 'Descriptor Count'], axis=1).copy()\n","    return x,y\n","  except:\n","    y = df.drop(['IsomericSMILES', 'Descriptors', 'CID'], axis=1).copy()\n","    return x,y\n","\n","def get_morgan(df):\n","  \"\"\"\n","  This function takes in a dataframe and returns\n","  a featurized dataframe with morgan fingerprints.\n","\n","  :param df: A molecular dataset for odor prediction with SMILES strings\n","  :type df: pandas Dataframe\n","  :return: A featurized dataframe.\n","  :rtype: pandas dataframes\n","  \"\"\"\n","  df['molecule'] = df['IsomericSMILES'].apply(lambda x: Chem.MolFromSmiles(x))\n","  df['MorganFP'] = df['molecule'].apply(lambda x: rdMolDescriptors.GetMorganFingerprintAsBitVect(x,radius=4,nBits=2048,useFeatures=True,useChirality=True))\n","\n","  df_list = []\n","\n","  for i in range(df.shape[0]):\n","    array = np.array(df['MorganFP'][i])\n","    df_i = pd.DataFrame(array)\n","    df_i = df_i.T\n","    df_list.append(df_i)\n","  morganfp = pd.concat(df_list, ignore_index=True)\n","\n","  return morganfp\n","\n","def iterative_train_test_split(X, y, test_size):\n","  \"\"\"\n","  Function doing a train-test split\n","  using the second order iterative\n","  stratification method.\n","\n","  :param df: X and y dataframes for a multilabel machine learning task\n","  :type df: pandas Dataframes\n","  :return: train-test split dataframes\n","  :rtype: pandas dataframes\n","  \"\"\"\n","  stratifier = IterativeStratification(n_splits=2, order=2, sample_distribution_per_fold=[test_size, 1.0-test_size])\n","  train_indexes, test_indexes = next(stratifier.split(X, y))\n","\n","  X_train, y_train = X.iloc[train_indexes], y.iloc[train_indexes]\n","  X_test, y_test = X.iloc[test_indexes], y.iloc[test_indexes]\n","\n","  return X_train, y_train, X_test, y_test"],"metadata":{"id":"hrDnTef4OrpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["umbrella_scores = {}\n","umbrella_scores['f1_macro'] = []\n","umbrella_scores['auroc_macro'] = []\n","umbrella_scores['precision_macro'] = []\n","umbrella_scores['recall_macro'] = []\n","umbrella_scores['f1_micro'] = []\n","umbrella_scores['auroc_micro'] = []\n","umbrella_scores['precision_micro'] = []\n","umbrella_scores['recall_micro'] = []"],"metadata":{"id":"Pd-lGbk_o4uC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv('alldesc_dataset.csv')\n","umbrella = pd.read_csv('computer_dataset_11.csv')"],"metadata":{"id":"PTPf47bYbGEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['Descriptors'] = dataset['Descriptors'].apply(format_list)\n","dataset = dataset[['CID', 'IsomericSMILES', 'Descriptors']]\n","\n","X, y = x_y_split(umbrella)\n","morgan = get_morgan(X)\n","train_x, train_y, test_x, test_y = iterative_train_test_split(morgan, y, 0.2)\n","clf = RandomForestClassifier(random_state=0)\n","clf.fit(train_x, train_y)\n","\n","y_hat = clf.predict(test_x)\n","\n","f1score_macro = MultilabelF1Score(num_labels=len(train_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.float))\n","auroc_macro = MultilabelAUROC(num_labels=len(train_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.long))\n","precision_macro = MultilabelPrecision(num_labels=len(train_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.long))\n","recall_macro = MultilabelRecall(num_labels=len(train_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.long))\n","\n","f1score_micro = MultilabelF1Score(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.float))\n","auroc_micro = MultilabelAUROC(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.long))\n","precision_micro = MultilabelPrecision(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.long))\n","recall_micro = MultilabelRecall(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.long))\n","\n","umbrella_scores['f1_macro'].append(f1score_macro)\n","umbrella_scores['auroc_macro'].append(auroc_macro)\n","umbrella_scores['precision_macro'].append(precision_macro)\n","umbrella_scores['recall_macro'].append(recall_macro)\n","umbrella_scores['f1_micro'].append(f1score_micro)\n","umbrella_scores['auroc_micro'].append(auroc_micro)\n","umbrella_scores['precision_micro'].append(precision_micro)\n","umbrella_scores['recall_micro'].append(recall_micro)"],"metadata":{"id":"nM67E6GGo85a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rand_scores = {}\n","rand_scores['f1_macro'] = []\n","rand_scores['auroc_macro'] = []\n","rand_scores['precision_macro'] = []\n","rand_scores['recall_macro'] = []\n","rand_scores['f1_micro'] = []\n","rand_scores['auroc_micro'] = []\n","rand_scores['precision_micro'] = []\n","rand_scores['recall_micro'] = []\n","\n","labels_df = pd.read_excel('computer_derived_ontology_11.xlsx')\n","labels_to_remove = labels_df[labels_df['Umbrella Terms'].isna()]['Original Descriptors']\n","labels_df = labels_df.dropna()"],"metadata":{"id":"6lH4GMFLptRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trials = 10\n","for count in range(trials):\n","    replace = labels_df.copy()\n","    replace['Umbrella Terms'] = np.random.permutation(replace['Umbrella Terms'] )\n","    replace = replace.values.tolist()\n","    # Changing to Umbrella terms and normalizing it once again\n","    rand = dataset.copy()\n","    rand['Descriptors'] = rand['Descriptors'].apply(lambda x: ';'.join([item for item in x.split(';') if item not in labels_to_remove.index]))\n","    rand = rand[rand['Descriptors'] != '']\n","    rand['Descriptors'] = rand['Descriptors'].apply(check_and_replace)\n","    rand['Descriptors'] = rand['Descriptors'].apply(make_unique)\n","    rand['Descriptors'] = rand['Descriptors'].dropna()\n","    rand = rand[rand['Descriptors'] != '']\n","    #rand['Descriptor Count'] = rand['Descriptors'].apply(lambda x: len(x.split(';')))\n","    rand['Descriptors'] = rand['Descriptors'].apply(lambda x: x.split(';'))\n","    mlb = MultiLabelBinarizer(sparse_output=True)\n","    mlb.fit(rand['Descriptors'])\n","    rand = rand.join(pd.DataFrame.sparse.from_spmatrix(mlb.transform(rand['Descriptors']), index=rand.index, columns=mlb.classes_))\n","    rand_x, rand_y = x_y_split(rand)\n","    rand_morgan = get_morgan(rand_x)\n","    rand_morgan_train_x, rand_morgan_train_y, rand_morgan_test_x, rand_morgan_test_y = iterative_train_test_split(rand_morgan, rand_y, 0.2)\n","    # Memory managing\n","    del rand_morgan\n","    del rand_y\n","    gc.collect()\n","\n","    clf = RandomForestClassifier(random_state=0)\n","    clf.fit(rand_morgan_train_x, rand_morgan_train_y.values)\n","\n","    y_hat = clf.predict(rand_morgan_test_x)\n","\n","    f1score = MultilabelF1Score(num_labels=len(rand_morgan_test_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.float))\n","    auroc_macro = MultilabelAUROC(num_labels=len(rand_morgan_test_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.long))\n","    precision_macro = MultilabelPrecision(num_labels=len(rand_morgan_test_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.long))\n","    recall_macro = MultilabelRecall(num_labels=len(rand_morgan_test_y.columns), average=\"macro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.long))\n","\n","    f1score_micro = MultilabelF1Score(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.float))\n","    auroc_micro = MultilabelAUROC(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.long))\n","    precision_micro = MultilabelPrecision(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.long))\n","    recall_micro = MultilabelRecall(num_labels=len(train_y.columns), average=\"micro\")(torch.tensor(y_hat, dtype=torch.float), torch.tensor(rand_morgan_test_y.values, dtype=torch.long))\n","\n","    rand_scores['f1_macro'].append(float(f1score_macro))\n","    rand_scores['auroc_macro'].append(float(auroc_macro))\n","    rand_scores['precision_macro'].append(float(precision_macro))\n","    rand_scores['recall_macro'].append(float(recall_macro))\n","    rand_scores['f1_micro'].append(float(f1score_micro))\n","    rand_scores['auroc_micro'].append(float(auroc_micro))\n","    rand_scores['precision_micro'].append(float(precision_micro))\n","    rand_scores['recall_micro'].append(float(recall_micro))\n"],"metadata":{"id":"y1vcW-YLp4FG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key in umbrella_scores:\n","   z_statistic, p_value = stests.ztest(rand_scores[key], value=umbrella_scores[key])\n","   print(key)\n","   print(\"Umbrella score\", umbrella_scores[key])\n","   print(\"Random scores mean\", statistics.mean(rand_scores[key]))\n","   print(\"Random scores st\n","   dev\", statistics.stdev(rand_scores[key]))\n","   print(\"Z-statistic:\", z_statistic)\n","   print(\"P-value:\", p_value)"],"metadata":{"id":"6vdNPWkirn8-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713737971318,"user_tz":-120,"elapsed":26,"user":{"displayName":"A Sajan","userId":"06499805654190845226"}},"outputId":"8ce87ea8-b341-452b-a0d0-c594b67b5915"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["f1_macro\n","Umbrella score [tensor(0.4616)]\n","Random scores mean 0.46160274744033813\n","Random scores stdev 0.0\n","Z-statistic: [nan]\n","P-value: [nan]\n","auroc_macro\n","Umbrella score [tensor(0.6489)]\n","Random scores mean 0.6008251667022705\n","Random scores stdev 0.00798470585119466\n","Z-statistic: [-19.042835]\n","P-value: [7.5336863e-81]\n","precision_macro\n","Umbrella score [tensor(0.5607)]\n","Random scores mean 0.5003776222467422\n","Random scores stdev 0.025906122651449027\n","Z-statistic: [-7.3678956]\n","P-value: [1.73342441e-13]\n","recall_macro\n","Umbrella score [tensor(0.4033)]\n","Random scores mean 0.40049120485782624\n","Random scores stdev 0.014226067766120646\n","Z-statistic: [-0.62128943]\n","P-value: [0.53440921]\n","f1_micro\n","Umbrella score [tensor(0.5356)]\n","Random scores mean 0.528855049610138\n","Random scores stdev 0.021633981876177686\n","Z-statistic: [-0.9869191]\n","P-value: [0.3236823]\n","auroc_micro\n","Umbrella score [tensor(0.6885)]\n","Random scores mean 0.6711460888385773\n","Random scores stdev 0.013849106374872562\n","Z-statistic: [-3.9689913]\n","P-value: [7.21775229e-05]\n","precision_micro\n","Umbrella score [tensor(0.6193)]\n","Random scores mean 0.5543984949588776\n","Random scores stdev 0.02360005354543286\n","Z-statistic: [-8.694341]\n","P-value: [3.48849438e-18]\n","recall_micro\n","Umbrella score [tensor(0.4719)]\n","Random scores mean 0.505767872929573\n","Random scores stdev 0.022460244519044444\n","Z-statistic: [4.775373]\n","P-value: [1.79374481e-06]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/stats/weightstats.py:748: RuntimeWarning: invalid value encountered in divide\n","  zstat = (value1 - value2 - diff) / std_diff\n"]}]},{"cell_type":"code","source":["with open('/scistor/informatica/asa521/macro_comp_scores.pkl', 'wb') as fp:\n","    pickle.dump(rand_scores, fp)\n","    print('scores saved successfully to file')"],"metadata":{"id":"XhFVVaoXrsxK"},"execution_count":null,"outputs":[]}]}